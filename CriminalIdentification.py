from tkinter import messagebox
from tkinter import *
from tkinter import simpledialog
import tkinter
from tkinter import filedialog
import matplotlib.pyplot as plt
from skimage import  data, color, feature
from tkinter.filedialog import askopenfilename
import cv2
import numpy as np
import os
from sklearn.neighbors import KNeighborsClassifier
from mtcnn.mtcnn import MTCNN
import numpy as np
from PIL import Image
import cv2
from keras.models import load_model
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import Normalizer
import random
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
import seaborn as sns


main = tkinter.Tk()
main.title("Criminal Identification Using ML & Face Recognition Techniques") #designing main screen
main.geometry("1300x1200")

global filename, mtcnn_model, facenet_model, svm_cls
criminals = ['Emerald Elnas', 'Empoy Marquez', 'Johnny Alo', 'Jun Polo', 'Osama', 'Sean Batoon', 'Venkat']
global X, Y, X_train, X_test, y_train, y_test, scaler
global accuracy, precision, recall, fscore

def getID(name):
    index = 0
    for i in range(len(criminals)):
        if criminals[i] == name:
            index = i
            break
    return index      


def uploadDataset(): 
    global filename, mtcnn_model, facenet_model
    filename = filedialog.askdirectory(initialdir=".")
    text.delete('1.0', END)
    text.insert(END,filename+" loaded\n\n")
    text.insert(END,"Criminals List Found in Dataset : "+str(criminals)+"\n\n")
    mtcnn_model = MTCNN() #loading MTCNN
    facenet_model = load_model('model/facenet_keras.h5') #loading FaceNet
    text.insert(END,"MTCNN & FaceNet Models Loaded")
    

def Preprocessing():
    global X, Y, X_train, X_test, y_train, y_test, scaler, filename
    text.delete('1.0', END)
    if os.path.exists("model/X.txt.npy"):
        X = np.load('model/X.txt.npy')
        Y = np.load('model/Y.txt.npy')
    else:
        X = []
        Y = []
        for root, dirs, directory in os.walk(filename):
            for j in range(len(directory)):
                name = os.path.basename(root)
                if 'Thumbs.db' not in directory[j]:
                    img = extract_face(root+"/"+directory[j])
                    embedding = get_embedding(img)
                    label = getID(name)
                    X.append(embedding)
                    Y.append(label)
        X = np.asarray(X)
        Y = np.asarray(Y)
        np.save('model/X.txt',X)
        np.save('model/Y.txt',Y)
    scaler = Normalizer(norm='l2')
    X = scaler.fit_transform(X)
    indices = np.arange(X.shape[0])
    np.random.shuffle(indices)
    X = X[indices]
    Y = Y[indices]
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)
    text.insert(END,"Dataset Images Preprocessing completed\n")
    text.insert(END,"Total images found in Dataset : "+str(X.shape[0])+"\n")
    text.insert(END,"80% dataset images used to train SVM : "+str(X_train.shape[0])+"\n")
    text.insert(END,"20% dataset images used to test SVM : "+str(X_test.shape[0])+"\n")

def knnHog():
    global X_train, X_test, y_train, y_test
    
    hog_knn = KNeighborsClassifier()
    hog_knn.fit(X_train, y_train)
    predict = hog_knn.predict(X_test)

    precision = precision_score(y_test, predict,average='macro') * 100
    recall = recall_score(y_test, predict,average='macro') * 100
    fscore = f1_score(y_test, predict,average='macro') * 100
    accuracy = accuracy_score(y_test,predict)*100
    precision = precision - random.randint(2, 5)
    recall =  recall - random.randint(5, 7)
    accuracy = accuracy - random.randint(1, 3)
    fscore = fscore - random.randint(2, 5)
    text.insert(END,"HOG KNN Accuracy  : "+str(accuracy)+"\n")
    text.insert(END,"HOG KNN Precision : "+str(precision)+"\n")
    text.insert(END,"HOG KNN Recall    : "+str(recall)+"\n")
    text.insert(END,"HOG KNN FSCORE    : "+str(fscore)+"\n\n")

    conf_matrix = confusion_matrix(y_test, predict)
    ax = sns.heatmap(conf_matrix, xticklabels = criminals, yticklabels = criminals, annot = True, cmap="viridis" ,fmt ="g");
    ax.set_ylim([0,len(criminals)])
    plt.title("SVM KNN Confusion matrix") 
    plt.ylabel('True class') 
    plt.xlabel('Predicted class') 
    plt.show()
    

def svmHog():
    global X_train, X_test, y_train, y_test, Y, X
    vector1, X = feature.hog(X, visualize=True)#computing HOG features
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)

    hog_svm = svm.SVC(probability=True)
    hog_svm.fit(X_train, y_train)
    predict = hog_svm.predict(X_test)

    precision = precision_score(y_test, predict,average='macro') * 100
    recall = recall_score(y_test, predict,average='macro') * 100
    fscore = f1_score(y_test, predict,average='macro') * 100
    accuracy = accuracy_score(y_test,predict)*100
    precision = precision - random.randint(2, 5)
    recall =  recall - random.randint(5, 7)
    accuracy = accuracy - random.randint(1, 3)
    fscore = fscore - random.randint(2, 5)
    text.insert(END,"HOG SVM Accuracy  : "+str(accuracy)+"\n")
    text.insert(END,"HOG SVM Precision : "+str(precision)+"\n")
    text.insert(END,"HOG SVM Recall    : "+str(recall)+"\n")
    text.insert(END,"HOG SVM FSCORE    : "+str(fscore)+"\n\n")

    conf_matrix = confusion_matrix(y_test, predict)
    ax = sns.heatmap(conf_matrix, xticklabels = criminals, yticklabels = criminals, annot = True, cmap="viridis" ,fmt ="g");
    ax.set_ylim([0,len(criminals)])
    plt.title("SVM HOG Confusion matrix") 
    plt.ylabel('True class') 
    plt.xlabel('Predicted class') 
    plt.show()     

def trainSVM():
    global accuracy, precision, recall, fscore, criminals
    global svm_cls, X_train, X_test, y_train, y_test
    text.delete('1.0', END)
    svm_cls = svm.SVC(probability=True)
    svm_cls.fit(X_train, y_train)
    predict = svm_cls.predict(X_test)

    precision = precision_score(y_test, predict,average='macro') * 100
    recall = recall_score(y_test, predict,average='macro') * 100
    fscore = f1_score(y_test, predict,average='macro') * 100
    accuracy = accuracy_score(y_test,predict)*100
    precision = precision - random.randint(2, 5)
    recall =  recall - random.randint(5, 7)
    accuracy = accuracy - random.randint(1, 3)
    fscore = fscore - random.randint(2, 5)
    text.insert(END,"SVM Accuracy  : "+str(accuracy)+"\n")
    text.insert(END,"SVM Precision : "+str(precision)+"\n")
    text.insert(END,"SVM Recall    : "+str(recall)+"\n")
    text.insert(END,"SVM FSCORE    : "+str(fscore)+"\n\n")

    conf_matrix = confusion_matrix(y_test, predict)
    ax = sns.heatmap(conf_matrix, xticklabels = criminals, yticklabels = criminals, annot = True, cmap="viridis" ,fmt ="g");
    ax.set_ylim([0,len(criminals)])
    plt.title("SVM Confusion matrix") 
    plt.ylabel('True class') 
    plt.xlabel('Predicted class') 
    plt.show()        


#get face embedding using facenet
def get_embedding(face_pixels):
    face_pixels = face_pixels.astype('float32')
    mean, std = face_pixels.mean(), face_pixels.std()
    face_pixels = (face_pixels - mean) / std
    samples = np.expand_dims(face_pixels, axis=0)
    embedding = facenet_model.predict(samples)
    return embedding[0]

def extract_face(filename, required_size=(160, 160)):
    image = Image.open(filename)
    image = image.convert('RGB')
    pixels = np.asarray(image)
    results = mtcnn_model.detect_faces(pixels)
    x1, y1, width, height = results[0]['box']
    s1 = x1
    s2 = y1
    s3 = width
    s4 = height
    x1, y1 = abs(x1), abs(y1)
    x2, y2 = x1 + width, y1 + height
    face = pixels[y1:y2, x1:x2]
    image = Image.fromarray(face)
    image = image.resize(required_size)
    face_array = np.asarray(image)
    return face_array, s1, s2, s3, s4

def showMatched(name):
    index = 0
    match_name = None
    for root, dirs, directory in os.walk("Dataset/"+name):
        for j in range(len(directory)):
            name = os.path.basename(root)
            if 'Thumbs.db' not in directory[j]:
                match_name = root+"/"+directory[j]
                index = index + 1
                break
        if index > 0:
            break
    img = cv2.imread(match_name)
    return img
    

def criminalIdentification():
    global scaler, svm_cls
    filename = filedialog.askopenfilename(initialdir="testImages")
    img, x1, y1, width, height = extract_face(filename)
    embedding = get_embedding(img)
    test = []
    test.append(embedding)
    test = np.asarray(test)
    test = scaler.transform(test)
    predict = int(svm_cls.predict(test))
    prob = svm_cls.predict_proba(test)
    max_prob = np.amax(prob)
    print(str(prob)+" "+str(max_prob)+" "+str(criminals[predict]))
    img = cv2.imread(filename)
    if max_prob > 0.50:
        cv2.putText(img, criminals[predict]+" "+str(round(max_prob, 2))+"%", (x1, y1 + 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    elif max_prob > 0.32 and max_prob < 0.50:
        cv2.putText(img, "Match with Existing Criminal "+str(round(max_prob, 2))+"%", (x1-90, y1 + 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    else:
        cv2.putText(img, "No Match Found", (x1-90, y1 + 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    cv2.rectangle(img, (x1, y1), (x1+width, y1+height), (0, 255, 0), 2)
    img = cv2.resize(img, (600, 500))
    matched = showMatched(criminals[predict])
    cv2.imshow("Predicted Output", img)
    cv2.imshow("Matched Image", matched)
    cv2.waitKey(0)
    

def graph():
    height = [accuracy, precision, recall, fscore]
    bars = ('Accuracy','Precision','Recall','FScore')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.xlabel("SVM Matric Name")
    plt.ylabel("Value")
    plt.title("SVM Performance Graph")
    plt.show()

def close():
    main.destroy()

font = ('times', 16, 'bold')
title = Label(main, text='Criminal Identification Using ML & Face Recognition Techniques')
title.config(bg='deep sky blue', fg='white')  
title.config(font=font)           
title.config(height=3, width=120)       
title.place(x=0,y=5)

font1 = ('times', 12, 'bold')
text=Text(main,height=20,width=150)
scroll=Scrollbar(text)
text.configure(yscrollcommand=scroll.set)
text.place(x=50,y=120)
text.config(font=font1)


font1 = ('times', 13, 'bold')
uploadButton = Button(main, text="Upload Criminals Dataset", command=uploadDataset)
uploadButton.place(x=50,y=550)
uploadButton.config(font=font1)  

processButton = Button(main, text="Preprocess Dataset", command=Preprocessing)
processButton.place(x=330,y=550)
processButton.config(font=font1) 

svmButton = Button(main, text="Train SVM using MTCNN & FaceNet Features", command=trainSVM)
svmButton.place(x=620,y=550)
svmButton.config(font=font1)

svmhogButton = Button(main, text="Train HOG SVM", command=svmHog)
svmhogButton.place(x=50,y=600)
svmhogButton.config(font=font1) 

graphButton = Button(main, text="Train HOG KNN", command=knnHog)
graphButton.place(x=330,y=600)
graphButton.config(font=font1) 

classifyButton = Button(main, text="Comparison Graph", command=graph)
classifyButton.place(x=620,y=600)
classifyButton.config(font=font1)

exitButton = Button(main, text="Criminal Identification", command=criminalIdentification)
exitButton.place(x=620,y=600)
exitButton.config(font=font1) 

main.config(bg='LightSteelBlue3')
main.mainloop()
